<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>[Python3]Ajax请求信息的爬取 | Yhchdev</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">[Python3]Ajax请求信息的爬取</h1><a id="logo" href="/.">Yhchdev</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/jinengshu/"><i class="fa fa-tree"> 技能</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">[Python3]Ajax请求信息的爬取</h1><div class="post-meta">Jul 2, 2018</div><div class="post-content"><h4 id="动态加载页面信息的提取"><a href="#动态加载页面信息的提取" class="headerlink" title="动态加载页面信息的提取"></a>动态加载页面信息的提取</h4><p>当我们浏览一个新闻类的网站，例如微博，今日头条，知乎等，由于它的内容极多，当我们搜索某一关键词的信息后，服务器只会向我们返回少量的数据，微博和头条是返回指定数量的数据，当我们再次向下刷新的时候，会再次通过Ajax请求返回指定数目的数据（如果你的网络不好时，会出现一个表示正在加载的小圆圈的动画效果）。知乎是当浏览器的滚动条触底时，再次提取数据。这就产生了一个问题，通过爬虫如何来提取通过Ajax请求动态加载的数据呢？</p>
<h4 id="模拟Ajax请求"><a href="#模拟Ajax请求" class="headerlink" title="模拟Ajax请求"></a>模拟Ajax请求</h4><p>这时需要通过Chrome等浏览器的开发者工具，利用Chrome开发者工具的筛选功能筛选出所有的Ajax请求。选择network选项，直接点击XHR分析网页后台向接口发送的Ajax请求，用requests来模拟Ajax请求，那么就可以成功抓取信息了</p>
<h4 id="待爬取网站的Ajax请求的分析"><a href="#待爬取网站的Ajax请求的分析" class="headerlink" title="待爬取网站的Ajax请求的分析"></a>待爬取网站的Ajax请求的分析</h4><p>这里选择今日头条来搞事情，通过爬虫来下载头条上的街拍图片，搜索关键词街拍，分析Ajax请求。下面是提取到的Ajax的主要信息</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Request URL: https://www.toutiao.com/search_content/?</span><br><span class="line">offset=0&amp;</span><br><span class="line">format=json&amp;</span><br><span class="line">keyword=%E8%A1%97%E6%8B%8D&amp;</span><br><span class="line">autoload=true&amp;</span><br><span class="line">count=20&amp;</span><br><span class="line">cur_tab=1&amp;</span><br><span class="line">from=search_tab</span><br></pre></td></tr></table></figure>
<h5 id="1-分析请求"><a href="#1-分析请求" class="headerlink" title="1.分析请求"></a>1.分析请求</h5><p><strong><a href="https://www.toutiao.com/search_content/" target="_blank" rel="noopener">https://www.toutiao.com/search_content/</a></strong>  这个是请求的链接，后面还带了一个 <strong>?</strong> 号，之后的都是请求所带的参数<br><img src="/2018/07/02/Python3-Ajax请求信息的爬取/pic1.PNG" alt="picone"><br>通过刷新新内容不断的发送Ajax请求，对比不同的几个ajax请求，对比他们Python3-Ajax请求信息的爬取的不变的地方和改变的地方，为写程序做好准备。</p>
<ul>
<li><p>可以发现每加载一次内容参数<strong>offset</strong>加20，表示偏移量，每次取20条数据</p>
</li>
<li><p><strong>format</strong>是不变的，表示格式是json格式的，</p>
</li>
<li><p><strong>Keyword</strong>是我们搜索的关键字<br><strong>%E8%A1%97%E6%8B%8D&amp;</strong> ,，可能是中文的某种加密方式加密后的结果</p>
</li>
<li><p>发现<strong>offset</strong>加20就可以了，其他参数照搬，因为都是不变的参数</p>
</li>
</ul>
<h5 id="2-分析响应"><a href="#2-分析响应" class="headerlink" title="2.分析响应"></a>2.分析响应</h5><p><img src="/2018/07/02/Python3-Ajax请求信息的爬取/pic2.PNG" alt="pitwo"><br>点击Preview分析响应内容。我们要下载图片，发现图片链接都在image_list里，一篇文章的一张或多张图片都在里面，而外层是data属性，标题在title属性里，这里获取标题名作为文件夹名称进行存储 </p>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><ul>
<li>首先，实现方法get_page()来加载单个Ajax请求的结果。其中唯一变化的参数就是offset，所以我们将它当作参数传递，代码实现如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode  <span class="comment">#Python内置的HTTP请求库</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(offset)</span>:</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">'offset'</span>:offset,</span><br><span class="line">        <span class="string">'format'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'keyword'</span>:<span class="string">'街拍'</span>,</span><br><span class="line">        <span class="string">'autoload'</span>:<span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'count'</span>:<span class="string">'20'</span>,</span><br><span class="line">        <span class="string">'cur_tab'</span>:<span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'from'</span> : <span class="string">'search_tab'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">'https://www.toutiao.com/search_content/?'</span>+ urlencode(params)  <span class="comment">#拼接URL</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> r.json()  <span class="comment"># 返回json格式的响应内容</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li>urllib库</li>
</ul>
<p>Python内置的HTTP请求库，通常我们使用的是功能更为强大的<strong>requests</strong>库，用到<strong>urllib</strong>的parse工具模块，提供了许多URL处理方法，比如拆分、解析、合并等。用urlencode()方法构造请求的GET参数。</p>
<ul>
<li>接下来，再实现一个解析方法：提取每条数据的<strong>image_list</strong>字段中的每一张图片链接，将图片链接和图片所属的标题一并返回，同时构造一个生成器。实现代码如下：</li>
</ul>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   </span><br><span class="line">def get_images(jsondata):</span><br><span class="line"><span class="built_in">if</span> jsondata.<span class="built_in">get</span>(<span class="string">'data'</span>):</span><br><span class="line">    <span class="built_in">for</span> item in jsondata.<span class="built_in">get</span>(<span class="string">'data'</span>):</span><br><span class="line">        title = item.<span class="built_in">get</span>(<span class="string">'title'</span>)</span><br><span class="line">        images = item.<span class="built_in">get</span>(<span class="string">'image_list'</span>)</span><br><span class="line">        <span class="built_in">for</span> <span class="built_in">image</span> in images:</span><br><span class="line">            <span class="built_in">yield</span> &#123;</span><br><span class="line">                <span class="string">'image'</span> : <span class="built_in">image</span>.<span class="built_in">get</span>(<span class="string">'url'</span>),</span><br><span class="line">                <span class="string">'title'</span> : title</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>接下来，实现一个保存图片的方法save_image()，其中item就是前面get_images()方法返回的一个字典。在该方法中，首先根据item的title来创建文件夹，然后请求这个图片链接，获取图片的二进制数据，以二进制的形式写入文件。图片的名称可以使用其内容的MD5值，这样可以去除重复。</li>
</ul>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def save_image(<span class="keyword">item</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>)):</span><br><span class="line">    os.mkdir(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>))</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    image_url = <span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'image'</span>)</span><br><span class="line">    print(image_url)</span><br><span class="line">    r = requests.<span class="built_in">get</span>(<span class="string">'http:'</span>+image_url)</span><br><span class="line">    <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">        file_path = <span class="string">'&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'</span>.<span class="built_in">format</span>(<span class="keyword">item</span>.<span class="built_in">get</span>(<span class="string">'title'</span>),md5(r.content).hexdigest(),<span class="string">'jpg'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file_path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.<span class="built_in">write</span>(r.content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'Already Downloaded'</span>, file_path)</span><br><span class="line">except:</span><br><span class="line">    print(<span class="string">'Faild to Save Image'</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最后，构造一个offset数组，遍历offset，提取图片链接，并将其下载：<br><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def main(<span class="built_in">offset</span>):</span><br><span class="line">jsondata = get_page(<span class="built_in">offset</span>)</span><br><span class="line"><span class="keyword">for</span> <span class="keyword">item</span> <span class="keyword">in</span> get_images(jsondata):</span><br><span class="line">    print(<span class="keyword">item</span>)</span><br><span class="line">    save_image(<span class="keyword">item</span>)</span><br><span class="line"></span><br><span class="line">num_start = <span class="number">1</span></span><br><span class="line">num_end = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    <span class="built_in">num</span> = ([x * <span class="number">20</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(num_start,num_end + <span class="number">1</span>)])</span><br><span class="line">    pool.map(main,<span class="built_in">num</span>)</span><br><span class="line">    pool.<span class="built_in">close</span>()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<ul>
<li>整体代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">from</span> multiprocessing.pool <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(offset)</span>:</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">'offset'</span>:offset,</span><br><span class="line">        <span class="string">'format'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'keyword'</span>:<span class="string">'街拍'</span>,</span><br><span class="line">        <span class="string">'autoload'</span>:<span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'count'</span>:<span class="string">'20'</span>,</span><br><span class="line">        <span class="string">'cur_tab'</span>:<span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'from'</span> : <span class="string">'search_tab'</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">'https://www.toutiao.com/search_content/?'</span>+ urlencode(params)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> r.json()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_images</span><span class="params">(jsondata)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> jsondata.get(<span class="string">'data'</span>):</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> jsondata.get(<span class="string">'data'</span>):</span><br><span class="line">            title = item.get(<span class="string">'title'</span>)</span><br><span class="line">            images = item.get(<span class="string">'image_list'</span>)</span><br><span class="line">            <span class="keyword">for</span> image <span class="keyword">in</span> images:</span><br><span class="line">                <span class="keyword">yield</span> &#123;</span><br><span class="line">                    <span class="string">'image'</span> : image.get(<span class="string">'url'</span>),</span><br><span class="line">                    <span class="string">'title'</span> : title</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_image</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(item.get(<span class="string">'title'</span>)):</span><br><span class="line">        os.mkdir(item.get(<span class="string">'title'</span>))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        image_url = item.get(<span class="string">'image'</span>)</span><br><span class="line"></span><br><span class="line">        r = requests.get(<span class="string">'http:'</span>+ image_url)</span><br><span class="line">        <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">            file_path = <span class="string">'&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'</span>.format(item.get(<span class="string">'title'</span>),md5(r.content).hexdigest(),<span class="string">'jpg'</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">                <span class="keyword">with</span> open(file_path,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(r.content)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'Already Downloaded'</span>, file_path)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">'Faild to Save Image'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    jsondata = get_page(offset)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> get_images(jsondata):</span><br><span class="line">        print(item)</span><br><span class="line">        save_image(item)</span><br><span class="line"></span><br><span class="line">num_start = <span class="number">1</span></span><br><span class="line">num_end = <span class="number">20</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    num = ([x * <span class="number">20</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(num_start,num_end + <span class="number">1</span>)])</span><br><span class="line">    pool.map(main,num)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br></pre></td></tr></table></figure>    
<p>这里定义了分页的起始页数和终止页数，分别为num_start和num_end，还利用了多线程的线程池，调用其map()方法实现多线程下载</p>
<h4 id="运行效果"><a href="#运行效果" class="headerlink" title="运行效果"></a>运行效果</h4><p><img src="/2018/07/02/Python3-Ajax请求信息的爬取/pic3.PNG" alt="pitwo"></p>
<h4 id="投喂我"><a href="#投喂我" class="headerlink" title="投喂我"></a>投喂我</h4><p>写文不易，如果本文对你有帮助，点击Donate,微信和支付宝投喂我</p>
</div><iframe src="/donate/?AliPayQR=/img/AliPayQR.jpg&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=null&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div class="tags"></div><div class="post-nav"><a class="pre" href="/2018/07/08/Python3爬虫-selenium-chromedriver可见即可爬/">[Python3爬虫]selenium+chromedriver可见即可爬</a><a class="next" href="/2018/06/18/Python3爬虫-Beautiful-Soup解析库/">[Python3爬虫]Beautiful Soup解析库</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC8zNTcwNS8xMjI0MQ=="><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://yoursite.com"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/09/04/验证码识别-图形验证码识别01/">[验证码识别]图形验证码识别01</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/02/数据可视化-Seaborn简单介绍/">[数据可视化]Seaborn简单介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/27/数据分析-基于人物登场率生成《倚天》词云图/">[数据分析]基于人物登场率生成《倚天》词云图</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/19/Ubuntu-配置仿MacOS主题/">[Ubuntu]配置仿MacOS主题</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/07/Python3爬虫-selenium爬取淘宝商品信息/">[Python3爬虫]selenium爬取淘宝商品信息</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/03/JSP-搭建开发环境/">[JSP]搭建开发环境</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/28/随笔-倚天屠龙记读后感/">[随笔]倚天屠龙记读后感</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/19/Design-Pattern-单例模式/">[Design Pattern]单例模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/17/Design-Pattern-抽象工厂模式/">[Design Pattern]抽象工厂模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/10/DesignPattern-FactoryPattern/">[DesignPattern]FactoryPattern</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yhchdev.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async="async"></script><span id="busuanzi_container_site_pv">|访问量<span id="busuanzi_value_site_pv"></span></span><span id="busuanzi_container_site_uv">|访客数<span id="busuanzi_value_site_uv"> </span></span></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>